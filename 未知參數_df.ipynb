{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這個爬蟲可以抓到所有在中文維基百科「[分類:含有未知參數的引用的頁面](https://zh.wikipedia.org/wiki/Category:含有未知参数的引用的页面)」裡，因為誤用`df`參數而報錯的條目，將參數移除即可除錯。\n",
    "\n",
    "> for loop 的最後一段 `if(cnt >= 10): break` 只是控制輸出在10條以內，可以依使用上調整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1850 articles in 10 pages.\n"
     ]
    }
   ],
   "source": [
    "next_page = []\n",
    "url = \"https://zh.wikipedia.org/wiki/Category:含有未知参数的引用的页面\"\n",
    "next_page.append(url)\n",
    "page_num = 1\n",
    "num = 0\n",
    "pre_url = 'https://zh.wikipedia.org'\n",
    "\n",
    "check_url = []\n",
    "\n",
    "for page in next_page:\n",
    "    res = req.get(page)\n",
    "    soup = bs(res.text, \"lxml\")\n",
    "    once = 0\n",
    "    for link in soup.select('div#mw-pages a'):\n",
    "        link_title = link.get_text()\n",
    "        #print(link_title)\n",
    "\n",
    "        link_url = 'https://zh.wikipedia.org' + link.get('href')\n",
    "        #print(link_url)\n",
    "\n",
    "        if(link_title == \"下一页\" and once == 0) :\n",
    "            page_num += 1\n",
    "            next_page.append(link_url)\n",
    "            once += 1\n",
    "            break\n",
    "\n",
    "\n",
    "    for link in soup.select('div.mw-category-group li'):\n",
    "        num += 1\n",
    "\n",
    "        temp_url = link.a.get('href')\n",
    "        if(temp_url is not None):\n",
    "            temp_url = pre_url + temp_url\n",
    "            #print('https://zh.wikipedia.org' + link.a.get('href'))\n",
    "            temp_title = link.get_text()\n",
    "            #print(link.get_text())\n",
    "\n",
    "            check_url.append(temp_url)\n",
    "\n",
    "print(\"There are \" + str(num) + \" articles in \" + str(page_num) + \" pages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1999年10月逝世人物列表 - 维基百科，自由的百科全书\n",
      "https://zh.wikipedia.org/wiki/1999%E5%B9%B410%E6%9C%88%E9%80%9D%E4%B8%96%E4%BA%BA%E7%89%A9%E5%88%97%E8%A1%A8\n",
      "2 1999年12月逝世人物列表 - 维基百科，自由的百科全书\n",
      "https://zh.wikipedia.org/wiki/1999%E5%B9%B412%E6%9C%88%E9%80%9D%E4%B8%96%E4%BA%BA%E7%89%A9%E5%88%97%E8%A1%A8\n",
      "3 维基百科:互助客栈/求助/存档/2020年3月 - 维基百科，自由的百科全书\n",
      "https://zh.wikipedia.org/wiki/Wikipedia:%E4%BA%92%E5%8A%A9%E5%AE%A2%E6%A0%88/%E6%B1%82%E5%8A%A9/%E5%AD%98%E6%A1%A3/2020%E5%B9%B43%E6%9C%88\n",
      "4 亨利·約翰·凱薩 - 维基百科，自由的百科全书\n",
      "https://zh.wikipedia.org/wiki/%E4%BA%A8%E5%88%A9%C2%B7%E7%B4%84%E7%BF%B0%C2%B7%E5%87%B1%E8%96%A9\n",
      "5 人民公正黨 - 维基百科，自由的百科全书\n",
      "https://zh.wikipedia.org/wiki/%E4%BA%BA%E6%B0%91%E5%85%AC%E6%AD%A3%E9%BB%A8\n",
      "6 人類對海洋生物的影響 - 维基百科，自由的百科全书\n",
      "https://zh.wikipedia.org/wiki/%E4%BA%BA%E9%A1%9E%E5%B0%8D%E6%B5%B7%E6%B4%8B%E7%94%9F%E7%89%A9%E7%9A%84%E5%BD%B1%E9%9F%BF\n",
      "7 以色列航空航點 - 维基百科，自由的百科全书\n",
      "https://zh.wikipedia.org/wiki/%E4%BB%A5%E8%89%B2%E5%88%97%E8%88%AA%E7%A9%BA%E8%88%AA%E9%BB%9E\n",
      "8 以色列警察 - 维基百科，自由的百科全书\n",
      "https://zh.wikipedia.org/wiki/%E4%BB%A5%E8%89%B2%E5%88%97%E8%AD%A6%E5%AF%9F\n",
      "9 伊万·维济蒂乌 - 维基百科，自由的百科全书\n",
      "https://zh.wikipedia.org/wiki/%E4%BC%8A%E4%B8%87%C2%B7%E7%BB%B4%E6%B5%8E%E8%92%82%E4%B9%8C\n",
      "10 伊拉克战争 - 维基百科，自由的百科全书\n",
      "https://zh.wikipedia.org/wiki/%E4%BC%8A%E6%8B%89%E5%85%8B%E6%88%98%E4%BA%89\n",
      "==================================================\n",
      "There are 1850 articles, and 10 have errors.\n"
     ]
    }
   ],
   "source": [
    "wrong = 0\n",
    "for page in check_url:\n",
    "    res = req.get(page)\n",
    "    soup = bs(res.text, \"lxml\")\n",
    "\n",
    "    for link in soup.select('span.error.citation-comment'):\n",
    "        link_txt = link.get_text()\n",
    "        # ppring(link_txt)\n",
    "\n",
    "        if(link_txt.find(\"df\") != -1 and soup.title.text.find(\"Citation\") == -1):\n",
    "            wrong += 1\n",
    "            print(str(wrong) + \" \" + soup.title.text)\n",
    "            print(page)\n",
    "            break\n",
    "            \n",
    "    if(wrong >= 10): break\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"There are \" + str(num) + \" articles, and \" + str(wrong) + \" have errors.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
